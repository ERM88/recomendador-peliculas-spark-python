{"cells":[{"cell_type":"markdown","source":["# Motor de recomendación con PySpark"],"metadata":{}},{"cell_type":"markdown","source":["___\n## Introducción\n\nPara la realización de esta tarea se utilizará el [dataset](http://grouplens.org/datasets/movielens/100k/) que contiene 100000 puntuaciones de 1000 usuarios sobre 1700 películas de Movielens. Se recomienda leer el fichero README.txt para entender el dataset.\n\nEl objetivo es **crear un recomendador** utilizando PySpark para futuros usuarios basandose en los datos historicos. Se utilizara el algoritmo **ALS**.\n\nLos pasos a seguir son:\n1. Cargar los datos en un dataframe\n2. Transformar el dataframe para dejarlo listo si fuese necesario\n3. Crear un modelo para predecir la puntuacion de cada usuario-película\n4. Valorar la calidad con el conjunto de test\n\nComo extra se intetará sacar conclusiones sobre las puntuaciones y una serie características.\n\nPara la ejecución de la tarea se ha utilizado el **entorno de Databricks con Spark 2.2.1**"],"metadata":{}},{"cell_type":"markdown","source":["___\n## Preparación del entorno: paquetes y variables\n\nLo primero que vamos hacer es **importar todos los paquetes** necesarios y crear el contexto para los data frames (SQLContext)"],"metadata":{}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n%matplotlib inline\n\nimport re\nfrom pyspark.sql import SQLContext, Row\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.recommendation import ALS, ALSModel\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n\nsqlc = SQLContext(sc)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["A continuación se crean las **variables** para:\n* Las rutas y nombres de los siguientes ficheros: puntuaciones usuario-película, información de los usuarios, información de las películas, información de las categorías de las películas\n* El separador de los campos en los ficheros que pueden ser un pipe o un tabulador\n* El nombre y posición de las columnas de los ficheros; además del tipo de dato que será en el dataframe"],"metadata":{}},{"cell_type":"code","source":["# Rutas y nombres de los ficheros y separador por defecto que utiliza\nRUTA_FICHERO_PUNTUACION = '/FileStore/tables/u.data'\nRUTA_FICHERO_USUARIO = '/FileStore/tables/u.user'\nRUTA_FICHERO_ITEM = '/FileStore/tables/u.item'\nRUTA_FICHERO_GENERO = '/FileStore/tables/u.genre'\nSEPARADOR_TABULADOR = '\\t'\nSEPARADOR_PIPE = '|'\n\n# Variables con información de las columnas de los ficheros: \n#    - posicion 0: nombre de la columna en el fichero\n#    - posicion 1: posicion de la columna en el fichero\n#    - posicion 2: tipo dataframe\n#    - posicion 3: True si la columna puede ser nullable. Se utilizara al convertir de RDD a dataframe.\n# Se crea también una lista con ellos dentro por si se quiere iterar\n# Fichero puntuaciones\nCOL_PUNTUACION_USERID = ('userid', 0, IntegerType(), True)\nCOL_PUNTUACION_ITEMID = ('itemid', 1, IntegerType(), True)\nCOL_PUNTUACION_RATING = ('rating', 2, FloatType(), True)\nCOL_PUNTUACION_TIMESTAMP = ('timestamp', 3, IntegerType(), True)\nCOL_PUNTUACION_PREDICTION = ('prediction', None, None, None)\nCOL_PUNTUACION_NUMEROPUNTUACIONES = ('numero_puntuaciones', None, None, None)\nCOLS_PUNTUACION = (\n    COL_PUNTUACION_USERID, \n    COL_PUNTUACION_ITEMID, \n    COL_PUNTUACION_RATING, \n    COL_PUNTUACION_TIMESTAMP)\n# Fichero usuario\nCOL_USUARIO_ID = ('user_userid', 0, IntegerType(), True)\nCOL_USUARIO_AGE = ('age', 1, IntegerType(), True)\nCOL_USUARIO_GENDER = ('gender', 2, StringType(), True)\nCOL_USUARIO_OCCUPATION = ('occupation', 3, StringType(), True)\nCOL_USUARIO_ZIPCODE = ('zipcode', 4, StringType(), True)\nCOLS_USUARIO = (\n    COL_USUARIO_ID, \n    COL_USUARIO_AGE, \n    COL_USUARIO_GENDER, \n    COL_USUARIO_OCCUPATION,\n    COL_USUARIO_ZIPCODE)\n# Fichero genero\nCOL_GENERO_NAME = ('name', 0, StringType(), False)\nCOL_GENERO_ID = ('genre_genreid', 1, IntegerType(), False)\nCOLS_GENERO = (\n    COL_GENERO_NAME, \n    COL_GENERO_ID)\n# Fichero item\nCOL_ITEM_ID = ('item_itemid', 0, IntegerType(), False)\nCOL_ITEM_TITLE = ('title', 1, StringType(), False)\nCOL_ITEM_RELEASEDATE = ('releasedate', 2, StringType(), False)\nCOL_ITEM_VIDERELEASEDATE = ('videoreleasedate', 3, StringType(), False)\nCOL_ITEM_IMDBURL = ('imdburl', 4, StringType(), False)\nCOL_ITEM_UNKNOWN = ('unknown', 5, IntegerType(), False)\nCOL_ITEM_ACTION = ('action', 6, IntegerType(), False)\nCOL_ITEM_ADVENTURE = ('adventure', 7, IntegerType(), False)\nCOL_ITEM_ANIMATION = ('animation', 8, IntegerType(), False)\nCOL_ITEM_CHILDRENS = ('childrens', 9, IntegerType(), False)\nCOL_ITEM_COMEDY = ('comedy', 10, IntegerType(), False)\nCOL_ITEM_CRIME = ('crime', 11, IntegerType(), False)\nCOL_ITEM_DOCUMENTARY = ('documentary', 12, IntegerType(), False)\nCOL_ITEM_DRAMA = ('drama', 13, IntegerType(), False)\nCOL_ITEM_FANTASY = ('fantasy', 14, IntegerType(), False)\nCOL_ITEM_FILMNOIR = ('filmnoir', 15, IntegerType(), False)\nCOL_ITEM_HORROR = ('horror', 16, IntegerType(), False)\nCOL_ITEM_MUSICAL = ('musical', 17, IntegerType(), False)\nCOL_ITEM_MYSTERY = ('mystery', 18, IntegerType(), False)\nCOL_ITEM_ROMACE = ('Romance', 19, IntegerType(), False)\nCOL_ITEM_SCIFI = ('scifi', 20, IntegerType(), False)\nCOL_ITEM_THRILLER = ('thriller', 21, IntegerType(), False)\nCOL_ITEM_WAR = ('war', 22, IntegerType(), False)\nCOL_ITEM_WESTERN = ('western', 23, IntegerType(), False)\nCOL_ITEM_GENEROS = ('generos', None, ArrayType(StringType()), False)\nCOL_ITEM_GENERO = ('genero', None, None, None)\nCOLS_ITEM = (\n    COL_ITEM_ID, \n    COL_ITEM_TITLE,\n    COL_ITEM_RELEASEDATE,\n    COL_ITEM_VIDERELEASEDATE,\n    COL_ITEM_IMDBURL)\nCOLS_ITEM_TODOSGENEROS = (\n    COL_ITEM_UNKNOWN,\n    COL_ITEM_ACTION, \n    COL_ITEM_ADVENTURE,\n    COL_ITEM_ANIMATION,\n    COL_ITEM_CHILDRENS,\n    COL_ITEM_COMEDY,\n    COL_ITEM_CRIME,\n    COL_ITEM_DOCUMENTARY,\n    COL_ITEM_DRAMA,\n    COL_ITEM_FANTASY,\n    COL_ITEM_FILMNOIR,\n    COL_ITEM_HORROR,\n    COL_ITEM_MUSICAL,\n    COL_ITEM_MYSTERY,\n    COL_ITEM_ROMACE,\n    COL_ITEM_SCIFI,\n    COL_ITEM_THRILLER,\n    COL_ITEM_WAR,\n    COL_ITEM_WESTERN)\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["___\n## Carga del dataframe y acciones\n\nLo primero es cargar los dataframes:\n* **Puntuaciones**: se elimina el timestamp ya que se considera que no es importante.\n* **Usuarios**: no se eliminará ningún campo ya que todos los atributos (edad, sexo, profesión, código postal) pueden ser importantes a la hora de hacer un posterior análisis. Se podría discutir si el código postal es importante pero para mí sí lo es ya que dependiendo de la zona podrían tener gustos distintos.\n* **Item**: se eliminará release date, video release date y IMDb URL ya son atributos que no aportan mucha información. De nuevo, se podría debatir si la fecha es importante o no ya que puede haber usuarios a los que les guste sólo las películas antiguas; yo no lo he considerado así.\n* **Género**: los dos atributos son necesarios ya que uno es el id o posición en el fichero Item y el otro el nombre del género."],"metadata":{}},{"cell_type":"code","source":["# Se carga las puntuaciones utilizando COLS_PUNTUACION y después se elimina el timestamp\nesquemaPuntuacion = StructType()\nfor col in COLS_PUNTUACION:\n    esquemaPuntuacion.add(StructField(col[0], col[2], col[3]))\ndataframePuntuacion = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_TABULADOR). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_PUNTUACION, schema=esquemaPuntuacion)\ncabecerasReducidas = list()\nfor col in COLS_PUNTUACION:\n    if col[0] != COL_PUNTUACION_TIMESTAMP[0]:\n        cabecerasReducidas.append(col[0])\ndataframePuntuacion = dataframePuntuacion.select(cabecerasReducidas)\n\n# Se carga los usuarios utilizando COLS_USUARIO\nesquemaUsuario = StructType()\nfor col in COLS_USUARIO:\n    esquemaUsuario.add(StructField(col[0], col[2], col[3]))\ndataframeUsuario = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_USUARIO, schema=esquemaUsuario)\n\n# Se carga los items utilizando COLS_ITEM y COLS_ITEM_TODOSGENEROS\nesquemaItem = StructType()\nfor col in COLS_ITEM:\n    esquemaItem.add(StructField(col[0], col[2], col[3]))\nfor col in COLS_ITEM_TODOSGENEROS:\n    esquemaItem.add(StructField(col[0], col[2], col[3]))\ndataframeItem = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_ITEM, schema=esquemaItem)\ncabecerasReducidas = list()\nfor col in COLS_ITEM:\n    if col[0] == COL_ITEM_ID[0] or col[0] == COL_ITEM_TITLE[0]:\n        cabecerasReducidas.append(col[0])\nfor col in COLS_ITEM_TODOSGENEROS:\n    cabecerasReducidas.append(col[0])\ndataframeItem = dataframeItem.select(cabecerasReducidas)\n\n# Se carga los géneros utilizando COLS_GENERO\nesquemaGenero = StructType()\nfor col in COLS_GENERO:\n    esquemaGenero.add(StructField(col[0], col[2], col[3]))\ndataframeGenero = sqlc.read.format('com.databricks.spark.csv'). \\\n                option('delimiter', SEPARADOR_PIPE). \\\n                option('header', 'false'). \\\n                load(RUTA_FICHERO_GENERO, schema=esquemaGenero)\n\nprint dataframePuntuacion.show(4)\nprint dataframeUsuario.show(4)\nprint dataframeItem.show(4)\nprint dataframeGenero.show(4)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Se mira que no haya ningún NULL o NAN en rating y después se añade los atributos de los usuarios y de las películas al dataframe de puntuaciones por si los atributos pueden ser de utilidad al modelo ALS."],"metadata":{}},{"cell_type":"code","source":["# Número de NAN y NULL en rating\nprint 'Número de filas con NAN en las puntuaciones en la columna rating: {0}', dataframePuntuacion.where(isnan(COL_PUNTUACION_RATING[0])).count()\nprint 'Número de filas con NULL en las puntuaciones en la columna rating: {0}', dataframePuntuacion.where(isnull(COL_PUNTUACION_RATING[0])).count()\n\n# Join puntuaciones-usuarios-item\ndataframePuntuacionUsuarioItem = dataframePuntuacion. \\\n                                  join(dataframeUsuario, dataframePuntuacion.userid==dataframeUsuario.user_userid, 'left_outer'). \\\n                                  join(dataframeItem, dataframePuntuacion.itemid==dataframeItem.item_itemid, 'left_outer')\n# Se eliminan las columnas duplicadas\ncabecerasReducidas = list()\nfor col in dataframePuntuacionUsuarioItem.columns:\n    if col != COL_USUARIO_ID[0] and col !=COL_ITEM_ID[0] :\n        cabecerasReducidas.append(col)\ndataframePuntuacionUsuarioItem = dataframePuntuacionUsuarioItem.select(cabecerasReducidas)\n\nprint 'Columnas con el dataframe con joins: {0}', dataframePuntuacionUsuarioItem.columns\nprint 'Número de filas: {0}', dataframePuntuacionUsuarioItem.count()\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Se divide el dataframe entre entrenamiento y test."],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItem.cache()\n# Se divide el dataframe en entrenamiento y test\ndataframePuntuacionUsuarioItemDividido = dataframePuntuacionUsuarioItem.randomSplit([0.7, 0.3], 1234)\ndataframePuntuacionUsuarioItemEntrenamiento = dataframePuntuacionUsuarioItemDividido[0]\ndataframePuntuacionUsuarioItemTest = dataframePuntuacionUsuarioItemDividido[1]"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["___\n## Creación del modelo ALS\nPara crear el modelo se utilizará cross validator en el que se variarán varios parámetros: rank, maxIter, alpha y regParam.\n\nSe ha elegido la estrategia de eliminar la fila que cuyo valor sea NAN en la predicción por los siguientes motivos:\n* Se ha ejecutado 1 vez sin cross validation y se ha visto que de los 29874 puntuaciones del conjunto de test, sólo 57 no tienen valor (0,19%), por lo que no tiene que tener impacto a la hora de valorar el modelo.\n* Se utiliza cross validation por lo que se tiene que utilizar este método por que si no se obtendrá NAN para el RMSE cuando no se disponga del valor de un elemento.\n\nSe utiliza el dataframe con todos los datos de puntuaciones-usuarios-películas como se ha comentado antes. Tiene la desventajas: 1) tarda más en ejecutarse, 2) se necesitan todos estos datos cuando se quiere obtener la predicción de una puntuación para un usuario y 3) si se añade más géneros para las películas se tiene que volver a entrenar. Por su parte, se tendrían que obtener mejores resultados que sólo con el dato de usuario, item y puntuación. Dependiendo de las características del negocio (¿se tiene todos los datos de un usuario?, ¿las categorías son frecuentemente modificadas?) se reducirá o no las columnas del dataframe."],"metadata":{}},{"cell_type":"code","source":["# Evaluador y cross validation\nevaluatorRegression = RegressionEvaluator(labelCol=COL_PUNTUACION_RATING[0])\n\nals = ALS(userCol=COL_PUNTUACION_USERID[0], itemCol=COL_PUNTUACION_ITEMID[0], ratingCol=COL_PUNTUACION_RATING[0], coldStartStrategy='drop')\n# als = ALS(userCol=COL_PUNTUACION_USERID[0], itemCol=COL_PUNTUACION_ITEMID[0], ratingCol=COL_PUNTUACION_RATING[0])\ngrid = ParamGridBuilder(). \\\n        addGrid(als.rank, [5, 10, 15, 20]). \\\n        addGrid(als.maxIter, [5, 10]). \\\n        addGrid(als.alpha, [1.0, 2.0]). \\\n        addGrid(als.regParam, [0.1, 0.5, 1.0]). \\\n        build()\n# grid = ParamGridBuilder().addGrid(als.rank, [5, 20]).build()\ncrossValidator = CrossValidator(estimator=als, estimatorParamMaps=grid, evaluator=evaluatorRegression, numFolds=2)\ncrossValidatorModel = crossValidator.fit(dataframePuntuacionUsuarioItemEntrenamiento)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["___\n## Valoración del modelo\n\nComo se ha dicho, el modelo descarta las filas que no tienen niguna puntuación en el entrenamiento, por tanto el conjunto de test tendrá 0 NAN. A continuación se muestra como se haría si se hubiese elegido la opción NA y el describe para el de entrenamiento y test para el rating y la predicción:"],"metadata":{}},{"cell_type":"code","source":["# Se obtiene la predicción para entrenamiento y test\ndataframePuntuacionUsuarioItemEntrenamientoPrediccion = crossValidatorModel.bestModel.transform(dataframePuntuacionUsuarioItemEntrenamiento)\ndataframePuntuacionUsuarioItemTestPrediccion = crossValidatorModel.bestModel.transform(dataframePuntuacionUsuarioItemTest)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# Se muestra el número de filas y las que son NAN en el conjunto de entrenamiento y de test\nprint 'Conjunto de entrenamiento predicción -> Número de filas: {0}, número con NAN en predicción: {1}'.format(dataframePuntuacionUsuarioItemEntrenamientoPrediccion.count(), dataframePuntuacionUsuarioItemEntrenamientoPrediccion.where(isnan(COL_PUNTUACION_PREDICTION[0])).count())\nprint 'Conjunto de test predicción -> Número de filas: {0}, número con NAN en predicción: {1}'.format(dataframePuntuacionUsuarioItemTestPrediccion.count(), dataframePuntuacionUsuarioItemTestPrediccion.where(isnan(COL_PUNTUACION_PREDICTION[0])).count())\n\n# Describe método para rating y prediction\nprint dataframePuntuacionUsuarioItemEntrenamientoPrediccion.select(COL_PUNTUACION_RATING[0], COL_PUNTUACION_PREDICTION[0]).describe().show()\nprint dataframePuntuacionUsuarioItemTestPrediccion.select(COL_PUNTUACION_RATING[0], COL_PUNTUACION_PREDICTION[0]).describe().show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["**RMSE** para el conjunto de entrenamiento y el de test. Como se puede observar es más pequeño el primero como era de esperar. No obstante el valor es bastante alto en ambos casos:"],"metadata":{}},{"cell_type":"code","source":["# Se obtiene el RMSE sobre los dos conjuntos\nrmseEntrenamiento = evaluatorRegression.evaluate(dataframePuntuacionUsuarioItemEntrenamientoPrediccion, {evaluatorRegression.metricName: 'rmse'})\nrmseTest = evaluatorRegression.evaluate(dataframePuntuacionUsuarioItemTestPrediccion, {evaluatorRegression.metricName: 'rmse'})\n\nprint 'RMSE en training: {0}'.format(rmseEntrenamiento)\nprint 'RMSE en test: {0}'.format(rmseTest)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Por último se representan en un gráfico donde el modelo ideal tendría todos los puntos en la línea oblícua.\nSe tienen que hacer varias observaciones:\n* Mientras la puntuación real es discreta, la predicha es continua\n* El máximo de las predicciones es mayor que 5 y el mínimo menor que 1. Se podrían modificar para que estuviesen en ese rango\n* No se ajustan a la línea que se ha dicho"],"metadata":{}},{"cell_type":"code","source":["# Se crea la lista con la puntuación real y la predicha\nxEntrenamiento, yEntrenamiento = list(), list()\nfor entrenamientoPrediccion in dataframePuntuacionUsuarioItemEntrenamientoPrediccion.collect():\n    xEntrenamiento.append(entrenamientoPrediccion[COL_PUNTUACION_RATING[0]])\n    yEntrenamiento.append(entrenamientoPrediccion[COL_PUNTUACION_PREDICTION[0]])\nxTest, yTest = list(), list()\nfor testPrediccion in dataframePuntuacionUsuarioItemTestPrediccion.collect():\n    xTest.append(testPrediccion[COL_PUNTUACION_RATING[0]])\n    yTest.append(testPrediccion[COL_PUNTUACION_PREDICTION[0]])\n\n# Se crea el gráfico y se muestra\nplt.clf()\nplt.xlim(-1, 6)\nplt.ylim(-1, 6)\nplt.xlabel('Puntuacion real')\nplt.ylabel('Puntuacion segun el modelo')\nplt.title('Puntuacion real vs prediccion')\n\nplt.plot([0, 20], [0, 20], 'b')\n# Se pasan los datos de entrenamiento y test al gráfico\nplt.plot(xEntrenamiento, yEntrenamiento, 'go', label='Entrenamiento')\nplt.plot(xTest, yTest, 'ro', label='Test')\nplt.legend(loc='lower right')\n\nplt.show()\ndisplay()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["___\n## Análisis más exhaustivos"],"metadata":{}},{"cell_type":"markdown","source":["### Género de películas con mejor puntuación\nSe obtendrá un dataframe donde cada fila tendrá los valores item_id-película-género. Por cada película, habrá tantas filas como géneros tenga.\n\nPara ello:\n1. Se obtendrá un diccionario con los géneros donde la clave es el id o posición en el fichero de item y la clave será el género.\n2. El siguiente paso es añadir una columna con un array con los géneros que tiene cada película. Para ello se utilizará RDDs para posteriormente trasformalo en otro dataframe\n3. El último paso es hacer un explode."],"metadata":{}},{"cell_type":"code","source":["def trasformarFilaColumnasgeneroColumageneros(fila, diccionarionGenero, ultimoIndiceNoGenero=1):\n    \"\"\"\n    Esta función trasforma la fila con atributos donde los últimos son los géneros en la forma 0/1 en otra donde los géneros con valor 1\n    son unidos en una lista que contiene los nombres de los generos.\n\n    :param fila: fila del RDD con el formato atributo1, atributo2, ..., genero1 (0/1), genero2 (0/1)...\n    :param diccionarionGenero: diccionario donde el valor es la posicion del genero en la fila a partir del primer genero en la fila \n    y el valor el el nombre de ese genero. Por ejemplo genero1 sera el 0 en el diccionario, genero2 será el 1 en el diccionario...\n    :param ultimoIndiceNoGenero: ultimo índice de la fila que no es género. Por defecto es 1\n    :return: lista con los valores tal cual hasta ultimoIndiceNoGenero, y el último elemento es una lista con el nombre de los géneros\n    de este item\n    \"\"\"\n    indice = 0\n    indiceGenero = 0\n    lineaNueva = list()\n    generos = list()\n    for item in fila:\n        if indice>ultimoIndiceNoGenero:\n            if item==1:\n                genero = diccionarionGenero.get(indiceGenero)\n                if genero:\n                    generos.append(genero)\n            indiceGenero += 1\n        else:\n            lineaNueva.append(item)\n        indice += 1\n    lineaNueva.append(generos)\n    return lineaNueva\n  \n# Se crea un diccionario con los géneros donde la clave es la columna id y el valor el nombre del género\ndiccionarioGenero = dict()\nfor row in dataframeGenero.collect():\n    diccionarioGenero[row.genre_genreid] = row.name\nprint diccionarioGenero\n\n# Se obtiene el nombre de todos las columnas de los géneros en el dataframe de item\ncolumnas = list()\ncolumnas.append(COL_ITEM_ID[0])\ncolumnas.append(COL_ITEM_TITLE[0])\nfor col in COLS_ITEM_TODOSGENEROS:\n    columnas.append(col[0])\n# Se seleccionan solo las columnas que nos interesa: itemid, titulo, generos\ndataframeItemGenero = dataframeItem.select(columnas)\nrddItemGenero = dataframeItemGenero.rdd.map(lambda fila: trasformarFilaColumnasgeneroColumageneros(fila, diccionarionGenero=diccionarioGenero))\n\n# Se crea el dataframe desde el RDD\ncolumnas = list()\ncolumnas.append(COL_ITEM_ID[0])\ncolumnas.append(COL_ITEM_TITLE[0])\ncolumnas.append(COL_ITEM_GENEROS[0])\ndataframeItemGenero = rddItemGenero.toDF(columnas)\n# Se utiliza explode para obtener todas las categorías en filas distintas\ndataframeItemGenero = dataframeItemGenero.select(COL_ITEM_ID[0], COL_ITEM_TITLE[0], explode(dataframeItemGenero.generos).alias(COL_ITEM_GENERO[0]))\nprint 'Número de filas antes de hacer el explode {0} y después {1}'.format(dataframeItem.count(), dataframeItemGenero.count())\ndataframeItemGenero.cache()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["El siguiente paso es coger el dataframe con las predicciones de test (se podría haber cogido el de entrenamiento también pero por cuestión de tiempo de ejecución sólo se hará con el de test), eliminar las filas correspondientes a las películas y sustituirlos por los que se acaba de obtener."],"metadata":{}},{"cell_type":"code","source":["cabecerasReducidas = list()\nfor col in COLS_PUNTUACION:\n    if col[0] != COL_PUNTUACION_TIMESTAMP[0]:\n        cabecerasReducidas.append(col[0])\nfor col in COLS_USUARIO:\n    if col[0] != COL_USUARIO_ID[0]:\n        cabecerasReducidas.append(col[0])\ncabecerasReducidas.append(COL_PUNTUACION_PREDICTION[0])\ndataframePuntuacionUsuarioItemTestPrediccionGenero = dataframePuntuacionUsuarioItemTestPrediccion.select(cabecerasReducidas)\n\n# Se hace el join con el otro dataframe y se elimina itemid\ndataframePuntuacionUsuarioItemTestPrediccionGenero = dataframePuntuacionUsuarioItemTestPrediccionGenero.join(dataframeItemGenero, dataframePuntuacionUsuarioItemTestPrediccionGenero.itemid==dataframeItemGenero.item_itemid, 'inner')\n\nprint 'Número de filas antes en el conjunto de test antes de hacer el join {0} y después {1}'.format(dataframePuntuacionUsuarioItemTestPrediccion.count(), dataframePuntuacionUsuarioItemTestPrediccionGenero.count())\n\ndataframeItemGenero.unpersist()\ndataframePuntuacionUsuarioItemTestPrediccionGenero.cache()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["Vamos a ver cual son los **géneros mejor valorados** de media. Para ello, agrupamos por género y obtenemos la media tanto de rating como de predicción. Además se incluye el número de puntuaciones:"],"metadata":{}},{"cell_type":"code","source":["print dataframePuntuacionUsuarioItemTestPrediccionGenero.groupBy(COL_ITEM_GENERO[0]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0])).sort(COL_PUNTUACION_RATING[0], ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["Como se puede ver Film-Noir es el género como mejor valoración aunque es de las que menos opiniones se tiene.\n\nSe podría hacer también una agrupación por **género y código postal** para ver si en una zona predomina las buenas puntuaciones de un determinado género. Como puede haber películas que sólo lo hayan valorado 1 usuario por código postal, se ha decidido en poner un mínimo de votaciones que será 60:"],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup = dataframePuntuacionUsuarioItemTestPrediccionGenero.groupBy([COL_ITEM_GENERO[0], COL_USUARIO_ZIPCODE[0]]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0]))\n# .where(dataframePuntuacionUsuarioItemTestPrediccionGenero.numero_puntuaciones>20).sort(COL_PUNTUACION_RATING[0], ascending=False).show()\nprint dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.where(dataframePuntuacionUsuarioItemTestPrediccionGeneroGroup.numero_puntuaciones>60).sort(COL_PUNTUACION_RATING[0], ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### Películas mejor valoradas\nA continuación se va a obtener las **películas mejor valoradas** de media en el conjunto de test volviendo a coger el dataframe fruto de la transformación con el modelo con un mínimo de 60 votaciones:"],"metadata":{}},{"cell_type":"code","source":["dataframePuntuacionUsuarioItemTestPrediccionGroup = dataframePuntuacionUsuarioItemTestPrediccion.groupBy(COL_ITEM_TITLE[0]).agg(avg(COL_PUNTUACION_RATING[0]).alias(COL_PUNTUACION_RATING[0]), avg(COL_PUNTUACION_PREDICTION[0]).alias(COL_PUNTUACION_PREDICTION[0]), count('*').alias(COL_PUNTUACION_NUMEROPUNTUACIONES[0]))\nprint dataframePuntuacionUsuarioItemTestPrediccionGroup.where(dataframePuntuacionUsuarioItemTestPrediccionGroup.numero_puntuaciones>60).sort(COL_PUNTUACION_RATING[0], ascending=False).show()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["No están nada mal las películas que aparecen en las primeras posiciones: Schindler's List, Casablanca, Star Wars (1977)..."],"metadata":{}},{"cell_type":"markdown","source":["---\n## Conclusiones\n\nComo se ha visto es muy fácil construir un modelo de recomendación de películas, lo más difícil es de donde obtener los datos para contruirlo (cold start).\n\nA partir de los datos, se pueden obtener información muy atractiva para la empresas de este sector y poder recomendar películas, por ejemplo, dependiendo de la zona donde vive.\n\nSiguientes pasos:\n1. Mejorar la programación ya que en algunos casos se utilizan el nombre de la columnas y en otros la forma datafram.columna. Es preferible la primera forma.\n2. Hacer un estudio más exhaustivo sobre los datos y ver, por ejemplo, si el género de la película y el sexo de la persona tiene relación y mejorar el motor de recomendación."],"metadata":{}}],"metadata":{"name":"Motor de recomendación con PySpark","notebookId":2462964866169561},"nbformat":4,"nbformat_minor":0}
